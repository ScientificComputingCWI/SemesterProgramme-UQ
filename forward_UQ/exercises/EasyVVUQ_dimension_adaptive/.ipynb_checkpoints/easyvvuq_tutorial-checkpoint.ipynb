{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32c316e",
   "metadata": {},
   "source": [
    "# Tutorial: Dimension adaptive forward uncertainty propagation with EasyVVUQ\n",
    "\n",
    "Here we will use EasyVVUQ to perform sparse grid forward uncertainty quantification on a relatively cheap, yet high-dimensional model.\n",
    "\n",
    "**Note**: if you installed EasyVVUQ using a virtual environment, make sure that:\n",
    "\n",
    "1) you activated the virtual environment, and\n",
    "2) you started this notebook with `myenv/bin/jupyterlab`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270ea2d",
   "metadata": {},
   "source": [
    "## Sparse grid UQ on an HIV model\n",
    "\n",
    "Here we will look at a HIV model [1], taken from the [Active Subspace data set repository](https://github.com/paulcon/as-data-sets). It models the T-cell count over time (days), and has **27 input parameters spread out over 7 coupled ODEs.**\n",
    "\n",
    "### HIV model\n",
    "\n",
    "From [here](https://github.com/paulcon/as-data-sets/blob/master/HIV/HIV.ipynb) we find the following description of the model, see also [4]. The 7 coupled ordinary differential equations are given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{dT}{dt} &= s_1 + \\frac{p_1}{C_1+V}TV - \\delta_1T - (K_1V + K_2M_I)T,\\\\\n",
    "\\frac{dT_I}{dt} &= \\psi(K_1V + K_2M_I)T + \\alpha_1T_L-\\delta_2T_I-K_3T_ICTL,\\\\\n",
    "\\frac{dT_L}{dt} &= (1-\\psi)(K_1V+K_2M_I)T-\\alpha_1T_L-\\delta_3T_L,\\\\\n",
    "\\frac{dM}{dt} &= s_2+K_4MV-K_5MV-\\delta_4M,\\\\\n",
    "\\frac{dM_I}{dt} &= K_5MV-\\delta_5M_I-K_6M_ICTL,\\\\\n",
    "\\frac{dCTL}{dt} &= s_3 + (K_7T_I+K_8M_I)CTL-\\delta_6CTL,\\\\\n",
    "\\frac{dV}{dt} &= K_9T_I+K_{10}M_I-K_{11}TV-(K_{12}+K_{13})MV-\\delta_7V,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $T(t)$ is the CD4$^+$ T-cell population, $T_I$ is the actively infected T-cell population, $T_L$ represents latently-infected T-cells, $M$ is macrophages, $M_I$ is infected macrophages, $CTL$ is cytotoxic lymphocytes, and $V$ is virions. The model's 27 parameters are summarized in the table below.\n",
    "\n",
    "Parameter|Nominal Value|Distribution (U(min, max))\n",
    ":-------:|:-----------:|:-------------:\n",
    "$s_1$|  10 |  U(9.75, 10.25)\n",
    "$s_2$|   .15 |  U(.14625, .15375)\n",
    "$s_3$|   5  | U(4.875, 5.125)\n",
    "$p_1$|   .2 |  U(.195, .205)\n",
    "$C_1$|   55.6  | U(54.21, 56.99)\n",
    "$K_1$|   3.87e-3 |  U(3.77325e-3, 3.96675e-3)\n",
    "$K_2$|   1e-6  | U(.975e-6, 1.025e-6)\n",
    "$K_3$|   4.5e-4 |  U(4.3875e-4, 4.6125e-4)\n",
    "$K_4$|   7.45e-4 |  U(7.26375e-4, 7.63625e-4)\n",
    "$K_5$|   5.22e-4 |  U(5.0895e-4, 5.3505e-4)\n",
    "$K_6$|   3e-6  | U(2.925e-6, 3.075e-6)\n",
    "$K_7$|   3.3e-4  | U(3.2175e-4, 3.3825e-4)\n",
    "$K_8$|   6e-9  | U(5.85e-9, 6.15e-9)\n",
    "$K_9$|   .537 |  U(.523575, .550425)\n",
    "$K_{10}$|   .285 |  U(.277875, .292125)\n",
    "$K_{11}$|   7.79e-6 |  U(7.59525e-6, 7.98475e-6)\n",
    "$K_{12}$|   1e-6  | U(.975e-6, 1.025e-6)\n",
    "$K_{13}$|   4e-5   |U(3.9e-5, 4.1e-5)\n",
    "$\\delta_1$|   .01 |  U(.00975, .01025)\n",
    "$\\delta_2$|   .28  | U(.273, .287)\n",
    "$\\delta_3$|   .05  | U(.04875, .05125)\n",
    "$\\delta_4$|   .005  | U(.004875, .005125)\n",
    "$\\delta_5$|   .005 |  U(.004875, .005125)\n",
    "$\\delta_6$|   .015 |  U(.014625, .015375)\n",
    "$\\delta_7$|   2.39 |  U(2.33025, 2.44975)\n",
    "$\\alpha_1$|   3e-4 |  U(2.925e-4, 3.075e-4)\n",
    "$\\psi$|   .97 |  U(.94575, .99425)\n",
    "\n",
    "The limits on the **uniform distributions are 2.5% above and below the nominal values**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10fca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import easyvvuq as uq\n",
    "import chaospy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from easyvvuq.actions import CreateRunDirectory, Encode, Decode, ExecuteLocal, Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcc8d6",
   "metadata": {},
   "source": [
    "### Setting up an EasyVVUQ campaign\n",
    "\n",
    "The fist couple of steps in a sparse grid campaign are no different than in the previous tutorial on the advection-diffusion model.\n",
    "\n",
    "We first set up the `params` dictionary, in which we specify the name, type and default value of each input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb54dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default values\n",
    "nominal = np.array([10, .15, 5, .2, 55.6, 3.87e-3, 1e-6, 4.5e-4, 7.45e-4, 5.22e-4, 3e-6,\\\n",
    "    3.3e-4, 6e-9, .537, .285, 7.79e-6, 1e-6, 4e-5, .01, .28, .05, .005, .005, .015, 2.39,\\\n",
    "    3e-4, .97])\n",
    "\n",
    "# parameter names\n",
    "param_names = ['s_1', 's_2', 's_3', 'p_1', 'C_1', 'K_1', 'K_2', 'K_3', 'K_4', 'K_5', 'K_6',\n",
    "               'K_7', 'K_8', 'K_9', 'K_10', 'K_11', 'K_12', 'K_13', 'delta_1', 'delta_2', 'delta_3',\n",
    "               'delta_4', 'delta_5', 'delta_6', 'delta_7', 'alpha_1', 'psi']\n",
    "# params dict\n",
    "params = {}\n",
    "for idx, name in enumerate(param_names):\n",
    "    params[name] = {'type': 'float', 'default': nominal[idx]}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a77274",
   "metadata": {},
   "source": [
    "Next we'll set up the **encoder**, which will create the input files for the HIV model using an input template. In this case the input file is just a comma-separated file of values. To create an EasyVVUQ input template each value is replaced by `$param_name`:\n",
    "\n",
    "`$s_1,$s_2,$s_3,$p_1,$C_1,$K_1,$K_2,$K_3,$K_4,$K_5,$K_6,$K_7,$K_8,$K_9,$K_10,$K_11,$K_12,$K_13,$delta_1,$delta_2,$delta_3,$delta_4,$delta_5,$delta_6,$delta_7,$alpha_1,$psi`\n",
    "\n",
    "The encoder will swap out the `$param_name` flags for values drawn from the specified input distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file encoder\n",
    "encoder = uq.encoders.GenericEncoder(template_fname='HIV_model/HIV.template', delimiter='$', target_filename='input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7bb05",
   "metadata": {},
   "source": [
    "The HIV model writes a CSV file containing the predicted T-cell count. The **decoder** will read this file and store its contents within the EasyVVUQ database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de9ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantity of Interest, also the column name of the output CSV file\n",
    "QOI = 'T_cell_count'\n",
    "# CSV output file decoder\n",
    "decoder = uq.decoders.SimpleCSV(target_filename='output.csv', output_columns=[QOI])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3accd88",
   "metadata": {},
   "source": [
    "We'll run the HIV ensemble locally. However, in many cases of practical interest the model will be too expensive for local execution. In this case the VECMA tools [QCG-PilotJob](https://github.com/vecma-project/QCG-PilotJob) or [FabSim3](https://github.com/djgroen/FabSim3) can be used in combination with EasyVVUQ to submit the ensemble to HPC resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e27086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local execution of HIV_model.py\n",
    "execute = ExecuteLocal('python {}/HIV_model/HIV_model.py'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2285b4f",
   "metadata": {},
   "source": [
    "Now we are combine all actions we want to execute into an `Actions` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8936be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location where the run directories are stored\n",
    "WORK_DIR = '/tmp'\n",
    "# actions to be undertaken: make rundirs, encode input files, execute local model ensemble, decode output files\n",
    "actions = Actions(CreateRunDirectory(root=WORK_DIR, flatten=True), Encode(encoder), execute, Decode(decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164afba",
   "metadata": {},
   "source": [
    "The central object in the UQ analysis is a so-called Campaign. This is created as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = uq.Campaign(name='HIV_SC', work_dir=WORK_DIR, params=params, actions=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72051f67",
   "metadata": {},
   "source": [
    "### Input specification\n",
    "\n",
    "Next we specify a probability density functions input parameter in the `vary` dict. Here we'll just include 2 inputs to visualize the full sampling plan, and specify a uniform input distribution with bounds at $\\pm 2.5 \\%$ from their default value.\n",
    "\n",
    "**Assignment** Create a `vary` dict for `K_4` and `delta_7` with the mentioned input distributions. Note that the nominal values are stored in `nominal`.\n",
    "\n",
    "**Question**: what will the encoder do with the other 25 inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vary = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77cd1e0",
   "metadata": {},
   "source": [
    "### Isotropic sparse-grid sampler\n",
    "\n",
    "This is where we deviate from the previous tutorial. We will first make an isotropic sparse grid sampler, i.e. one that:\n",
    "\n",
    "* is more sparse than the standard `uq.sampling.SCSampler`, yet\n",
    "* still treats each input in the same manner.\n",
    "\n",
    "To generate the sampling plan we select the (sparse) Stochastic Collocation sampler. \n",
    "\n",
    "**Assignment**: Create a `uq.sampling.SCSampler` object with the following properties:\n",
    "\n",
    "* `sparse=True`: speaks for itself\n",
    "* `polynomial_order=1`: in the case of `sparse=True`, this is an overloaded term. By setting `polynomial_order=1` we are essentially starting with 1 code sample, i.e. $\\Lambda=\\{(0,0)\\}$ as a multi indiex set.\n",
    "* `quadrature_rule='C'`: select the Clenshaw Curtis (CC) quadrature rule\n",
    "* `growth=True`: selects an exponential growth rule, making CC **nested**. This is *not* possible for every quadrature rule, see [Chaospy documentation](https://chaospy.readthedocs.io/en/master/reference/quadrature/index.html).\n",
    "\n",
    "Don't forget to attach the sampler to the campaign with `campaign.set_sampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fbf71-8cb3-46af-bb69-4fa977ebb468",
   "metadata": {},
   "source": [
    "Below is just a subroutine to plot a 2D sampling plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd374652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampling_plan(sampler):\n",
    "    \"\"\"\n",
    "    Plot the sampling plan of the (first) two input dimensions\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax = fig.add_subplot(111, xlabel='x_1', ylabel='x_2')\n",
    "    # the xi_d array contains the N x d sampling points, with N being the number of points and d the number of inputs\n",
    "    ax.plot(sampler.xi_d[:,0], sampler.xi_d[:, 1], 'ro')\n",
    "    # print the number of points to screen\n",
    "    print(\"Number of sampling points = %d\" % sampler.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b09d2-2193-4589-b83e-fc2c416b127e",
   "metadata": {},
   "source": [
    "This is a subroutine for plotting a 2 or 3 dimensional multi index set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2192086-2c19-4a61-a97d-b24b5b17e24a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_multi_idx(multi_idx, c='lightgray', fill = False, lbl = \"\", alpha=0.8, **kwargs):\n",
    "    \"\"\"\n",
    "    Visualize a 2D or 3D multi index set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib axis\n",
    "        The axis to plot on.\n",
    "    multi_idx : array\n",
    "        The array of multi indices.\n",
    "    c : string, optional\n",
    "        Color. The default is 'lightgray'.\n",
    "    fill : boolean\n",
    "        Fill the squares. if multi index is 2D. Default is False.\n",
    "    lbl : string\n",
    "        A label for the filled squares. Default = \"\"\n",
    "    alpha : float\n",
    "        Makes the 3D voxels opague by lowering alpha. Default is 0.8.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "\n",
    "    d = multi_idx[0].size\n",
    "\n",
    "    if d == 2:\n",
    "\n",
    "        ax = fig.add_subplot(111)\n",
    "        \n",
    "        ax.set_xticks(np.arange(6))\n",
    "        ax.set_yticks(np.arange(6))\n",
    "        ax.set_xlabel(r'$l_1$', fontsize=18)\n",
    "        ax.set_ylabel(r'$l_2$', fontsize=18, rotation=0)\n",
    "\n",
    "        for idx in multi_idx:\n",
    "            idx0 = idx[0]; idx1 = idx[1]\n",
    "            # plot midpoint\n",
    "            if not fill:\n",
    "                if 'mid_point' in kwargs:\n",
    "                    ax.text(idx0, idx1, '%s' % kwargs['mid_point'][tuple(idx)], \n",
    "                            horizontalalignment='center', verticalalignment='center')\n",
    "                else:\n",
    "                    ax.plot(idx0, idx1, 'x', color=c, label=r'${\\bf l}\\in\\Lambda$')\n",
    "\n",
    "            # plot single square\n",
    "            ax.plot([idx0 - 0.5, idx0 + 0.5], [idx1 - 0.5, idx1 - 0.5], color=c)\n",
    "            ax.plot([idx0 + 0.5, idx0 + 0.5], [idx1 - 0.5, idx1 + 0.5], color=c)\n",
    "            ax.plot([idx0 + 0.5, idx0 - 0.5], [idx1 + 0.5, idx1 + 0.5], color=c)\n",
    "            ax.plot([idx0 - 0.5, idx0 - 0.5], [idx1 + 0.5, idx1 - 0.5], color=c)\n",
    "\n",
    "            if fill:\n",
    "                ax.fill([idx0 - 0.5, idx0 + 0.5, idx0 + 0.5, idx0 + 0.5, idx0 + 0.5, idx0 + 0.5, idx0 - 0.5, idx0 - 0.5],\n",
    "                        [idx1 - 0.5, idx1 - 0.5, idx1 - 0.5, idx1 + 0.5, idx1 + 0.5, idx1 + 0.5, idx1 + 0.5, idx1 - 0.5],\n",
    "                        color=c, label=lbl)\n",
    "\n",
    "        plt.axis('scaled')\n",
    "        plt.xlim([-0.5, 5.5])\n",
    "        plt.ylim([-0.5, 5.5])\n",
    "        plt.tight_layout()\n",
    "\n",
    "    elif d == 3:\n",
    "\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        ax.set_xticks(np.arange(6) + 0.5)\n",
    "        ax.set_xticklabels(np.arange(6))\n",
    "        ax.set_yticks(np.arange(6) + 0.5)\n",
    "        ax.set_yticklabels(np.arange(6))\n",
    "        ax.set_zticks(np.arange(6) + 0.5)\n",
    "        ax.set_zticklabels(np.arange(6))\n",
    "        \n",
    "        ax.set_xlabel(r'$i_1$', fontsize=18)\n",
    "        ax.set_ylabel(r'$i_2$', fontsize=18)\n",
    "        ax.set_zlabel(r'$i_3$', fontsize=18)\n",
    "        \n",
    "        ax.view_init(elev=30, azim=45)\n",
    "        \n",
    "        # Remove colored axes planes\n",
    "        ax.xaxis.pane.fill = False\n",
    "        ax.yaxis.pane.fill = False\n",
    "        ax.zaxis.pane.fill = False\n",
    "        \n",
    "        # Set color to white \n",
    "        ax.xaxis.pane.set_edgecolor('w')\n",
    "        ax.yaxis.pane.set_edgecolor('w')\n",
    "        ax.zaxis.pane.set_edgecolor('w')\n",
    "\n",
    "        # create 6 layers of 6 x 6 voxels\n",
    "        N = np.max(multi_idx) + 1\n",
    "        voxels = np.zeros([N,N,N], dtype=bool)\n",
    "        for idx in multi_idx:\n",
    "            # set to True to display voxel\n",
    "            voxels[idx[0], idx[1], idx[2]] = True\n",
    "\n",
    "        #plot cubes\n",
    "        ax.voxels(voxels, facecolors=c, edgecolor='k', alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb83b7e-2c96-41da-8482-a5f0ed48a4c4",
   "metadata": {},
   "source": [
    "Plot the initial sampling plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampling_plan(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c58498-78a4-42bd-b8dd-5e8a663a1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you do not like the cartoony feel of the plot, remove \"with plt.xkcd():\"\n",
    "with plt.xkcd():   \n",
    "    plot_multi_idx(sampler.l_norm - 1, c='gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa6aa7",
   "metadata": {},
   "source": [
    "We can refine the grid to the next isotropic level via `sampler.next_level_sparse_grid()`.\n",
    "\n",
    "**Assigment**: \n",
    "\n",
    "* refine the sparse-grid once, and plot the grid and the multi index set using the subroutines above. Remember that to actually execute the ensembles you must run `campaign.execute().collate(progress_bar=True)`.\n",
    "* Next, perform an analysis step, and plot the first order Sobol indices. These are vector-valued in time, each entry represent 1 day. Which input is dominant?\n",
    "* Also plot the sum of the first-order indices. What do you see?\n",
    "* Refine the grid once more (just execute the cell with your `next_level_sparse_grid` again). Replot the Sobol indices. Can you explain the change in the sum of the first-order indices?\n",
    "* Refine the grid 3 more times. How many points do you get in the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adf3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_adaptations = 1\n",
    "for i in range(n_adaptations):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72443566-f033-431a-9cfa-4148b036c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = campaign.analyse(qoi_cols=[QOI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86ab70-7489-4ed6-92c7-403391a7092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobols_first = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955de67",
   "metadata": {},
   "source": [
    "## Dimension-adaptive sparse grids\n",
    "\n",
    "The sparse grids shown above are **isotropic**, in the sense that both inputs are treated the same. While isotropic sparse grids contains less points compared to the standard SC method, they will not scale very well when we have 27 inputs. \n",
    "\n",
    "In this case we can opt to apply the dimension-adaptive version of the SC sampler, in order to create an **anisotropic** sparse grid. This process is iterative in nature, usually staring from a single point. Unlike the isotropic case, only a certain (combination of) parameters will get refined. \n",
    "\n",
    "At each iteration, the code is evaluated at certain (so-called *admissible*) refinements, the `x` symbols in the cartoon below. Refinement means adding another tensor product where the quadrature order of one or more inputs is increased by one. Only one of the admissible refinements will get accepted, creating an anisotropic sampling plan.\n",
    "\n",
    "![](images/adapt.png)\n",
    "\n",
    "To determine which of the admissible refinement gets accepted, an error measure is computed for every refinement. The one with the highest error is accepted. Here we will use *hierarchical surplus*, as explained in the class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e27825",
   "metadata": {},
   "source": [
    "We will create a new campaign, the `params` dict and the `actions` do not need to redefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = uq.Campaign(name='HIV_SC_adaptive', params=params, actions=actions, work_dir='/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0db61",
   "metadata": {},
   "source": [
    "**Assignment**: redefine `vary`, include all 27 inputs at with Uniform distributions at $\\pm$ 2.5 percent of the values in `nominal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb0a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vary = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdb440",
   "metadata": {},
   "source": [
    "**Assigment**: make a new sparse-grid SC sampler, except this time also add the keyword `dimension_adaptive = True`. Add the sampler to the campaign and execute the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed3727",
   "metadata": {},
   "source": [
    "To analyse the results (and execute the dimension adaptivity), we need a separate `SCAnalysis` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = uq.analysis.SCAnalysis(sampler=sampler, qoi_cols=[QOI])\n",
    "# perform analysis (basically estimates moments, Sobol analysis, and updates internal state of analysis)\n",
    "campaign.apply_analysis(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75470e-3a2d-4d36-94db-fa211e6e0c41",
   "metadata": {},
   "source": [
    "We are now at the starting point of a dimension-adaptive campaign of a 27-dimensional input space, with an ensemble consisting of just a single code sample. In other words, the accepted index set is $\\Lambda\\{(0,0,0,....,0)\\}$. This is stored in the (not very well named) `analysis.l_norm` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1bba6-8f16-41be-99e5-3f436271149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda (starts counting at 1 instead of 0, so this is equivalent to (0,0,0,...,0))\n",
    "analysis.l_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1901c2-6c2a-48fb-a33b-dff027159068",
   "metadata": {},
   "source": [
    "Now we'll refine the grid several times in an anisotropic fashion, placing samples only in the most important input directions. A single refinement step consists of the following sequence:\n",
    "\n",
    "* `sampler.look_ahead(multi indices)`: this determines the new admissible candidate multi-indices (the new admissible forward neighbours). It take the current multi index set as an arugument (what was called $\\Lambda$ in the class). Remember this is stored in the `analysis.l_norm` array.\n",
    "*  Execute the ensemble in the usual way\n",
    "* `campaign.get_collation_result()`: get the Pandas data frame with all up-to-date code samples.\n",
    "* `adapt_dimension(QOI, data_frame)`: computes the hierarchical surplus at all candidate refinements, and accepts the one with the highest surplus.\n",
    "\n",
    "**Assigment**: make a loop of these steps that refines the grid a specified number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_adaptations = 30\n",
    "for i in range(number_of_adaptations):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edcca32",
   "metadata": {},
   "source": [
    "This command retrieves the result after all refinements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b99d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = campaign.get_last_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449fbe9-1b61-4b8f-8c1d-f5d1a5e46e1d",
   "metadata": {},
   "source": [
    "**Assignment**: examine the ensemble sizes of each iteration. These are stored in `sampler.n_new_points`. Explain what you see. What is the smalles enemble size. Can you explain it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e1b83-aafa-4340-8cb1-d1d2b89ae655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "451e7213-1f4a-42e9-a781-56cd6b7d9024",
   "metadata": {},
   "source": [
    "Still, at every iteration one multi index is added to $\\Lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9714555",
   "metadata": {},
   "source": [
    "The `adaptation_table` shows a plot of that visualizes which inputs got refined. Again, each refinement is another tensor product of 1D quadrature points, where the quadrature order of at least 1 input is increased. Note that the algorithm will focus on a subset of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c86643-f184-4d48-bc2d-a96142383f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def adaptation_table(vary, multi_idx, **kwargs):\n",
    "        \"\"\"Plots a color-coded table of the quadrature-order refinement.\n",
    "        Shows in what order the parameters were refined, and unlike\n",
    "        adaptation_histogram, this also shows higher-order refinements.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        **kwargs: can contain kwarg 'order' to specify the order in which\n",
    "        the variables on the x axis are plotted (e.g. in order of decreasing\n",
    "        1st order Sobol index).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        D = multi_idx[0].size\n",
    "        \n",
    "        # if specified, plot the variables on the x axis in a given order\n",
    "        if 'order' in kwargs:\n",
    "            order = kwargs['order']\n",
    "        else:\n",
    "            order = range(D)\n",
    "\n",
    "        l = np.copy(multi_idx)[:, order]\n",
    "        import matplotlib as mpl\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig = plt.figure(figsize=[12, 6])\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        # max quad order\n",
    "        M = np.max(l)\n",
    "        cmap = plt.get_cmap('Purples', M)\n",
    "        # plot 'heat map' of refinement\n",
    "        plt.imshow(l.T, cmap=cmap, aspect='auto')\n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=M - 1)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        # cb = plt.colorbar(sm, cax=ax)\n",
    "        # plot the quad order in the middle of the colorbar intervals\n",
    "        p = np.linspace(0, M - 1, M + 1)\n",
    "        tick_p = 0.5 * (p[1:] + p[0:-1])\n",
    "        # cb.set_ticks(tick_p)\n",
    "        # cb.set_ticklabels(np.arange(M))\n",
    "        # cb.set_label(r'quadrature order')\n",
    "        # plot the variables names on the x axis\n",
    "        ax.set_yticks(range(l.shape[1]))\n",
    "        params = np.array([key for key in vary.keys()])\n",
    "        ax.set_yticklabels(params[order], fontsize=12)\n",
    "        # ax.set_yticks(range(l.shape[0]))\n",
    "        ax.set_xlabel('iteration')\n",
    "        # plt.yticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a166c7c-c536-4501-8cb3-d7bc8b2303fc",
   "metadata": {},
   "source": [
    "**Assignment** Run this command below, to visualize the refinement process. Different colors represent different quadrature orders of the entries of the accepted multi indices. What happens from iteration 0 onward? Would you say there is an low effective dimension, despite having a 27 dimensional space? Make sure you've executed enough interations to confidently answer this question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0aa6d-fd11-45db-91ca-c0a3e43cc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_table(vary, analysis.l_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95acd12",
   "metadata": {},
   "source": [
    "Here we will compute confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_intervals(samples, conf=0.9):\n",
    "    \"\"\"\n",
    "    Compute the confidence intervals given an array of samples\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : array\n",
    "        Samples on which to compute the intervals.\n",
    "    conf : float, optional, must be in [0, 1].\n",
    "        The confidence interval percentage. The default is 0.9.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lower : array\n",
    "        The lower confidence bound..\n",
    "    upper : array\n",
    "        The upper confidence bound.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # ake sure conf is in [0, 1]\n",
    "    if conf < 0.0 or conf > 1.0:\n",
    "        print('conf must be specified within [0, 1]')\n",
    "        return\n",
    "\n",
    "    # lower bound = alpha, upper bound = 1 - alpha\n",
    "    alpha = 0.5 * (1.0 - conf)\n",
    "\n",
    "    # arrays for lower and upper bound of the interval\n",
    "    n_samples = samples.shape[0]\n",
    "    N_qoi = samples.shape[1]\n",
    "    lower = np.zeros(N_qoi)\n",
    "    upper = np.zeros(N_qoi)\n",
    "\n",
    "    # the probabilities of the ecdf\n",
    "    prob = np.linspace(0, 1, n_samples)\n",
    "    # the closest locations in prob that correspond to the interval bounds\n",
    "    idx0 = np.where(prob <= alpha)[0][-1]\n",
    "    idx1 = np.where(prob <= 1.0 - alpha)[0][-1]\n",
    "\n",
    "    # for every location of qoi compute the ecdf-based confidence interval\n",
    "    for i in range(N_qoi):\n",
    "        # the sorted surrogate samples at the current location\n",
    "        samples_sorted = np.sort(samples[:, i])\n",
    "        # the corresponding confidence interval\n",
    "        lower[i] = samples_sorted[idx0]\n",
    "        upper[i] = samples_sorted[idx1]\n",
    "\n",
    "    return lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089dc965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "x = range(analysis.N_qoi[QOI])\n",
    "\n",
    "code_samples = analysis.get_sample_array(QOI)\n",
    "n_samples = code_samples.shape[0]\n",
    "\n",
    "#confidence bounds\n",
    "lower1, upper1 = get_confidence_intervals(code_samples, conf=0.63)\n",
    "lower2, upper2 = get_confidence_intervals(code_samples, conf=0.95)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=1,\n",
    "                          width_ratios=[3, 1])\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0])\n",
    "ax2 = fig.add_subplot(spec[1], sharey=ax1)\n",
    "ax2.get_xaxis().set_ticks([])\n",
    "fig.subplots_adjust(wspace=0)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "ax1.fill_between(x, lower2, upper2, color='#aa99cc', label='95% CI', alpha=0.5)\n",
    "ax1.fill_between(x, lower1, upper1, color='#aa99cc', label='68% CI')\n",
    "\n",
    "mean = results.describe(QOI, 'mean')\n",
    "ax1.plot(x, mean, label='Mean')\n",
    "\n",
    "ax1.legend(loc=0, frameon=False)\n",
    "\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('T cell count')\n",
    "ax2.axis('off')\n",
    "ax2.hist(code_samples[:, -1], orientation='horizontal', color='#aa99cc')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b9e61",
   "metadata": {},
   "source": [
    "Finally, we will create a plot with all first-order Sobol indices `S_i`, which shows the fraction of the output variance (vs time here), that each input variable is responsible for *by itself*. To also estimate higher-order effects (the fraction of variance obtained by simultaneously varying 2 or more inputs together), we sum all first-order indices. Where this sum is close to one, there is (almost) no higher-order effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "# color = cycle(['b', 'r', 'g', 'm', 'c', 'k'])\n",
    "marker = cycle(['o', 'v', '^', '<', '>', 's', '*', 'p', 'd', 'P', 'X', \n",
    "                '1', '2', '3', '4', 'x', 'D', '|', '_'])\n",
    "skip = 100\n",
    "x = range(0, analysis.N_qoi[QOI], skip)\n",
    "\n",
    "fig = plt.figure(figsize=[10, 5])\n",
    "ax = fig.add_subplot(121, title=r'First-order Sobol indices',\n",
    "                      xlabel=\"days\", ylim=[0,1])\n",
    "ax.set_ylabel(r'$S_i$', fontsize=14)\n",
    "sobols_first = results.sobols_first(QOI)\n",
    "\n",
    "first_order_contribution = 0\n",
    "\n",
    "for param in sobols_first.keys():\n",
    "    ax.plot(x, sobols_first[param][0:-1:skip], label=param, marker=next(marker))\n",
    "    first_order_contribution += sobols_first[param][0:-1:skip]\n",
    "    \n",
    "ax.plot(x, first_order_contribution, 'b*', label=r'First-order contribution all 27 parameters')\n",
    "\n",
    "# place legend on empty axes on the right\n",
    "handles, labels = ax.get_legend_handles_labels()    # ax1 legend\n",
    "ax2 = fig.add_subplot(122)                          # ax2\n",
    "ax2.axis('off')                                     # make ax2 empty\n",
    "ax2.legend(handles, labels, ncol=2)                 # place ax1 legend on ax1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c5d4c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] T. Loudon and S. Pankavich. _Mathematical Analysis and Dynamic Active Subspaces for a Long term model of HIV_. arXiv:1604.04588, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea87be-6f79-4005-af00-af8a899e49ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
